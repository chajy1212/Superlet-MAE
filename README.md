# Superlet-MAE: Self-Supervised Masked Autoencoding for Sleep Staging Using Single-Channel EEG


## ğŸš€ Abstract
Sleep stage classification is essential for diagnosing sleep disorders, but traditional polysomnography (PSG) is time-consuming and labor-intensive and subject to inter-rater variability, limiting its reliability.
We propose a **_self-supervised learning (SSL) framework_** that integrates the **_Superlet Transform (SLT)_**, offering high-resolution time-frequency analysis, with a **_Masked Autoencoder (MAE)_** architecture.
Single-channel EEG signals (i.e., Fpz-Cz) from the Sleep-EDF dataset were transformed into Superlet scalograms and used for masked reconstruction pretraining.
Our method is the **_first to combine Superlet with MAE_** for EEG representation learning, enabling robust feature extraction from unlabeled data.
Experimental results show that the proposed approach outperforms conventional transforms such as **_Short-Time Fourier Transform (STFT)_** and **_Continuous Wavelet Transform (CWT)_**, achieving state-of-the-art performance in sleep staging.
These findings highlight the potential of Superlet-based SSL for scalable and accurate sleep analysis.


## ğŸ“Š Key Results

### ğŸ”¹ Comparison of Time-Frequency Representation Methods
| Transform Type |      Accuracy      |   Macro F1 Score   |   Cohenâ€™s Kappa   |
|:--------------:|:------------------:|:------------------:|:-----------------:|
| **_Superlet_** | **_75.87 Â± 1.39_** | **_63.23 Â± 1.74_** | **_0.64 Â± 0.02_** |
|      STFT      |    74.81 Â± 1.27    |    61.74 Â± 1.76    |    0.62 Â± 0.02    |
|      CWT       |    75.45 Â± 1.42    |    62.84 Â± 1.16    |    0.63 Â± 0.02    |

Superlet achieved the **_highest average scores across all metrics_**, with relatively smaller standard deviations, suggesting more consistent and robust classification performance.

---

### ğŸ”¹ Comparison with Other Self-supervised Methods
| Model      |      Accuracy      |   Macro F1 Score   |   Cohenâ€™s Kappa   |
|:----------:|:------------------:|:------------------:|:-----------------:|
| **_Ours_** | **_75.87 Â± 1.39_** | **_63.23 Â± 1.74_** | **_0.64 Â± 0.02_** |
| MAEEG      |    72.29 Â± 4.56    |    62.58 Â± 6.02    |    0.62 Â± 0.08    |
| TS-TCC     |    69.27 Â± 8.15    |   54.09 Â± 18.89    |    0.55 Â± 0.15    |
| BENDR      |    70.73 Â± 8.57    |    62.04 Â± 8.03    |    0.60 Â± 0.11    |

Superlet-MAE outperformed all baselines:  
- **+3.58%** higher ACC than **_MAEEG_**
- **+6.6%** higher ACC than **_TS-TCC_** 
- **+5.14%** higher ACC than **_BENDR_**


## ğŸ“ˆ Visualization

### ğŸ”¹ MAE Reconstruction
<p align="center">
  <img src="./figures/reconstruction.jpg" width="800"/>
</p>
<p align="center">
  <em>Visualization of MAE reconstruction performance (mask ratio = 0.75).<br>
  (A) original scalogram, (B) masked scalogram, (C) reconstructed scalogram.</em>
</p>

### ğŸ”¹ Sleep Stage Hypnogram
<p align="center">
  <img src="./figures/hypnogram.png" width="800"/>
</p>
<p align="center">
  <em>Visualization of sleep stage classification for subject #SC4632E0 in Sleep-EDFX.<br>
  (A) ground-truth hypnogram based on manual annotations by sleep experts,<br>
  (B) predicted hypnogram generated by the proposed MAE classifier,<br>
  (C) softmax probability distribution across sleep stage over time.</em>
</p>

## ğŸ“‚ Repository Structure
```
Superlet-MAE/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data_loader.py          # EEG dataset loader
â”‚   â”œâ”€â”€ morlet.py               # Morlet wavelet utilities
â”‚   â”œâ”€â”€ preprocess.py           # Convert raw Sleep-EDFX to .npz
â”‚   â”œâ”€â”€ superlet_transform.py   # Apply Superlet Transform
â”‚   â””â”€â”€ superlets.py            # Superlet implementation
â”‚
â”œâ”€â”€ figures/
â”‚   â”œâ”€â”€ hypnogram.jpg           # Example hypnogram plot
â”‚   â””â”€â”€ reconstruction.jpg      # Example reconstruction plot
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ model.py                # MAE (ViT backbone) implementation
â”‚   â””â”€â”€ pos_embed.py            # Positional embedding functions
â”‚
â”œâ”€â”€ training/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ linear_probing.py       # Linear probing evaluation
â”‚   â””â”€â”€ train.py                # MAE pretraining script
â”‚
â”œâ”€â”€ requirements.txt            # Dependencies
â””â”€â”€ README.md                   # Project documentation
```


## âš™ï¸ Installation
```
$ git clone https://github.com/chajy1212/Superlet-MAE.git
$ cd Superlet-MAE
$ pip install -r requirements.txt
```


## ğŸƒ Usage

### 1. Download Sleep EDFX Dataset  
Download the Sleep-EDFX dataset from [PhysioNet](https://www.physionet.org/content/sleep-edfx/1.0.0/).

### 2. Preprocess raw EEG data  
Use the preprocessing script to convert raw EDF files into NPZ format:
```bash
python data/preprocess.py
```

### 3. Apply Superlet Transform
Transform the preprocessed EEG data into timeâ€“frequency representations:
```bash
python data/superlet_transform.py
```

### 4. Pretrain the MAE Model
Run self-supervised pretraining of the Masked Autoencoder.  
Trained models are saved under `./models/`.
```bash
python training/train.py
```

### 5. Evaluate using Linear Probing
Train a shallow classifier on the encoderâ€™s latent features:
```bash
python training/linear_probing.py
```


## ğŸ“Œ Acknowledgements

This work was supported by BK21 Four Institute of Precision Public Health.
